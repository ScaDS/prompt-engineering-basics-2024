{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14addf66-dac0-43f1-8414-c8ae74139dff",
   "metadata": {},
   "source": [
    "# Analysing image data\n",
    "LLMs can also assist you in analysing image data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8aa79b-7c7f-42ac-bdaf-e546e9e47065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To analyze an image programmatically, you can use libraries like OpenCV and PIL (Pillow) in Python. Below is a sample code that demonstrates how to load an image, convert it to grayscale, and detect edges using OpenCV:\n",
       "\n",
       "```python\n",
       "import cv2\n",
       "from matplotlib import pyplot as plt\n",
       "\n",
       "# Load an image from file\n",
       "image_path = 'path_to_your_image.jpg'\n",
       "image = cv2.imread(image_path)\n",
       "\n",
       "# Convert the image to grayscale\n",
       "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
       "\n",
       "# Use Canny Edge Detection\n",
       "edges = cv2.Canny(gray_image, threshold1=100, threshold2=200)\n",
       "\n",
       "# Display the original image and the edge-detected image\n",
       "plt.figure(figsize=(10, 5))\n",
       "\n",
       "plt.subplot(1, 2, 1)\n",
       "plt.title('Original Image')\n",
       "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
       "\n",
       "plt.subplot(1, 2, 2)\n",
       "plt.title('Edge Detected Image')\n",
       "plt.imshow(edges, cmap='gray')\n",
       "\n",
       "plt.show()\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "- **OpenCV**: A powerful library for computer vision tasks. We use it to load images and perform image processing operations.\n",
       "- **cv2.imread()**: Reads an image from a file.\n",
       "- **cv2.cvtColor()**: Converts the image from one color space to another, here from BGR to Grayscale.\n",
       "- **cv2.Canny()**: Performs edge detection using the Canny algorithm.\n",
       "- **matplotlib.pyplot**: Used here for displaying images.\n",
       "\n",
       "### Requirements:\n",
       "- Ensure OpenCV and Matplotlib are installed. You can install them via pip if they are not already installed:\n",
       "  ```sh\n",
       "  pip install opencv-python-headless matplotlib\n",
       "  ```\n",
       "\n",
       "Replace `'path_to_your_image.jpg'` with the actual path to your image file. This code will display both the original and processed edge-detected images side by side. Adjust the `threshold1` and `threshold2` parameters in `cv2.Canny()` to fine-tune edge detection results based on specific needs or image characteristics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Write code for analysing an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30564b9-d48b-47fd-ab47-67919f7ef293",
   "metadata": {},
   "source": [
    "## Scientific image analysis using deep learning\n",
    "It might be important that you specify the desired profession and the goals of the analysis, what the images show and what kind of algorithm you want to use. Again, if you specify the task to weakly, the LLM may generate code that is good for anything or nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bceaaf4-bf7e-4639-9355-16ebaeefac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To achieve this task, we'll utilize a deep learning model, such as a U-Net, to perform semantic segmentation of the nuclei in the DAPI-stained image. Following segmentation, we'll extract quantitative metrics like intensity, size, and shape.\n",
       "\n",
       "Below is an example code to accomplish this task using Python and popular libraries such as TensorFlow/Keras for deep learning, OpenCV for image manipulation, and scikit-image for measurements.\n",
       "\n",
       "Ensure you have these packages installed in your environment:\n",
       "- TensorFlow: `pip install tensorflow`\n",
       "- OpenCV: `pip install opencv-python`\n",
       "- scikit-image: `pip install scikit-image`\n",
       "- NumPy: `pip install numpy`\n",
       "\n",
       "```python\n",
       "import tensorflow as tf\n",
       "import numpy as np\n",
       "import cv2\n",
       "from skimage import measure\n",
       "import matplotlib.pyplot as plt\n",
       "from tensorflow.keras.models import load_model\n",
       "\n",
       "# Load the pre-trained U-Net model\n",
       "model_path = 'path_to_your_trained_model.h5'\n",
       "model = load_model(model_path, compile=False)\n",
       "\n",
       "# Load and preprocess the input image\n",
       "def preprocess_image(image_path):\n",
       "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
       "    image = cv2.resize(image, (256, 256))  # Resize to the model's expected input size\n",
       "    image = image / 255.0  # Normalize the image\n",
       "    return np.expand_dims(image, axis=[0, -1])  # Add batch and channel dimensions\n",
       "\n",
       "# Predict and segment the nuclei\n",
       "def segment_nuclei(image):\n",
       "    prediction = model.predict(image)\n",
       "    segmentation = (prediction[0, :, :, 0] > 0.5).astype(np.uint8)  # Threshold prediction\n",
       "    return segmentation\n",
       "\n",
       "# Quantify nuclei properties\n",
       "def quantify_nuclei_properties(segmentation, original_image):\n",
       "    labeled_nuclei = measure.label(segmentation)\n",
       "    properties = measure.regionprops(labeled_nuclei, intensity_image=original_image)\n",
       "    \n",
       "    nucleus_data = []\n",
       "    for prop in properties:\n",
       "        nucleus_info = {\n",
       "            'centroid': prop.centroid,\n",
       "            'area': prop.area,\n",
       "            'mean_intensity': prop.mean_intensity,\n",
       "            'eccentricity': prop.eccentricity,\n",
       "            'solidity': prop.solidity\n",
       "        }\n",
       "        nucleus_data.append(nucleus_info)\n",
       "    return nucleus_data\n",
       "\n",
       "# Main analysis\n",
       "def analyze_image(image_path):\n",
       "    original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the original image for intensity measurements\n",
       "    image = preprocess_image(image_path)\n",
       "    segmentation = segment_nuclei(image)\n",
       "    \n",
       "    # Upscale segmentation to the original image size for accurate measurement\n",
       "    segmentation = cv2.resize(segmentation.astype(np.uint8), original_image.shape[::-1])\n",
       "    \n",
       "    nucleus_data = quantify_nuclei_properties(segmentation, original_image)\n",
       "    \n",
       "    # Visualize the results\n",
       "    plt.figure(figsize=(10, 5))\n",
       "    plt.subplot(1, 2, 1)\n",
       "    plt.imshow(original_image, cmap='gray')\n",
       "    plt.title('Original Image')\n",
       "    \n",
       "    plt.subplot(1, 2, 2)\n",
       "    plt.imshow(segmentation, cmap='gray')\n",
       "    plt.title('Nuclei Segmentation')\n",
       "    \n",
       "    plt.show()\n",
       "    \n",
       "    return nucleus_data\n",
       "\n",
       "# Example usage\n",
       "image_path = 'path_to_your_dapi_image.png'\n",
       "nuclei_properties = analyze_image(image_path)\n",
       "print(nuclei_properties)\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "- **Preprocessing:** We load the image in grayscale and normalize its pixel values to between 0 and 1.\n",
       "- **Deep Learning Prediction:** The image is passed through a U-Net model, which generates a binary mask (segmentation) of the nuclei.\n",
       "- **Labeling and Properties Extraction:** The `skimage.measure.label` function is used to label connected components in the segmentation mask. We then use `regionprops` to calculate properties such as area, mean intensity, eccentricity, and solidity for each labeled nucleus.\n",
       "- **Visualization and Results:** The original and segmented images are displayed, and a list of dictionaries containing the extracted properties for each nucleus is returned and printed.\n",
       "\n",
       "Make sure to replace the placeholders (`path_to_your_trained_model.h5`, `path_to_your_dapi_image.png`) with actual paths to your model and image files. You might need to adjust the image resizing steps depending on your model's expected input size."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "You are a bio-image analyst.\n",
    "You are about to analyse an image taken with a \n",
    "fluorescence microscope that shows nuclei in DAPI staining.\n",
    "You should use Deep Learning to segment the nuclei in the image.\n",
    "You should quantify intensity, size and shape of the segmented nuclei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b352b9-15ab-49be-8734-b5c196258b8f",
   "metadata": {},
   "source": [
    "## Modifying code style\n",
    "As shown earlier, you can ask the LLM to change the style of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6cd48b-9656-44da-9ea3-7f42d3269695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To segment and analyze nuclei in a DAPI-stained fluorescence microscope image using deep learning without defining functions explicitly, you can use a pre-trained deep learning model like U-Net for segmentation and then quantify intensity, size, and shape using libraries such as NumPy and OpenCV. Here's a concise Python script using PyTorch and OpenCV:\n",
       "\n",
       "```python\n",
       "import torch\n",
       "import numpy as np\n",
       "import cv2\n",
       "from torchvision import transforms\n",
       "from PIL import Image\n",
       "from skimage.measure import label, regionprops\n",
       "\n",
       "# Load image and pre-trained U-Net model\n",
       "image_path = 'path_to_image.png'\n",
       "model_path = 'path_to_model.pth'\n",
       "image = Image.open(image_path).convert('L')\n",
       "model = torch.load(model_path)\n",
       "model.eval()\n",
       "\n",
       "# Preprocess the image\n",
       "transform = transforms.Compose([\n",
       "    transforms.ToTensor(),\n",
       "    transforms.Resize((256, 256)),  # Resize to match the model input if necessary\n",
       "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
       "])\n",
       "\n",
       "input_image = transform(image).unsqueeze(0)\n",
       "\n",
       "# Segment the nuclei\n",
       "with torch.no_grad():\n",
       "    output = model(input_image)\n",
       "    segmented = output.squeeze().numpy() > 0.5  # Threshold the output\n",
       "\n",
       "# Convert segmentation to binary image\n",
       "segmented_img = segmented.astype(np.uint8) * 255\n",
       "\n",
       "# Label and analyze properties of segmented nuclei\n",
       "labeled_img = label(segmented_img)\n",
       "props = regionprops(labeled_img, intensity_image=np.array(image))\n",
       "\n",
       "# Quantify attributes\n",
       "for prop in props:\n",
       "    intensity = prop.mean_intensity\n",
       "    size = prop.area\n",
       "    eccentricity = prop.eccentricity\n",
       "\n",
       "    print(f'Intensity: {intensity}, Size: {size}, Eccentricity: {eccentricity}')\n",
       "```\n",
       "\n",
       "**Note**: This example assumes that you have a pre-trained U-Net model saved as a `.pth` file and an input image. You may need to adjust the transforms, model path, and image path appropriately.  \n",
       "\n",
       "**Additional Considerations**:\n",
       "- Ensure that the input dimensions match the modelâ€™s expected input dimensions (resize if necessary).\n",
       "- If using a different framework (e.g., TensorFlow), adjust the loading and inference code accordingly.\n",
       "- Pre-trained models for segmentation can often be found on platforms like PyTorch Hub or model zoos. These models should be compatible with your analytical goals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Make the code as short as possible and do not use functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cabf074-4ccf-4caa-b718-deb0bd997ba6",
   "metadata": {},
   "source": [
    "## Technical terms\n",
    "If you know basics of image analysis and deep learning, you can guide the LLM in generating the code even closer. It needs this guidance, because it cannot see the image and it does not have expertise such as which algorithm to use (e.g. [StarDist](https://github.com/stardist/stardist)) for which kind of image. This may change obviously as LLMs are an active research field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a8a85f-8736-41c7-8e65-69508f05d259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is a concise code snippet that uses the StarDist algorithm to segment nuclei in an image, then quantifies their intensity, size, and shape. This example assumes you have the necessary libraries installed and a pre-trained model available for use:\n",
       "\n",
       "```python\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "from stardist.models import StarDist2D\n",
       "from skimage import io, measure\n",
       "\n",
       "# Load the pre-trained StarDist model\n",
       "model = StarDist2D.from_pretrained('2D_versatile_fluo')\n",
       "\n",
       "# Read the image with DAPI staining\n",
       "image = io.imread('path/to/your/image.tif')\n",
       "\n",
       "# Segment nuclei using StarDist\n",
       "labels, _ = model.predict_instances(image)\n",
       "\n",
       "# Quantify intensity, size, and shape\n",
       "properties = measure.regionprops(labels, intensity_image=image)\n",
       "\n",
       "# Extract and print properties\n",
       "for prop in properties:\n",
       "    print(f\"Nucleus {prop.label}:\")\n",
       "    print(f\"  Intensity: {prop.mean_intensity}\")\n",
       "    print(f\"  Size (area): {prop.area}\")\n",
       "    print(f\"  Eccentricity (shape): {prop.eccentricity}\")\n",
       "\n",
       "# Optionally, display the segmented nuclei\n",
       "plt.imshow(labels, cmap='jet', alpha=0.5)\n",
       "plt.imshow(image, cmap='gray')\n",
       "plt.axis('off')\n",
       "plt.show()\n",
       "```\n",
       "This script does the following:\n",
       "- Loads a pre-trained StarDist model for 2D fluorescence microscopy images.\n",
       "- Reads the input image.\n",
       "- Segments the nuclei using the StarDist model.\n",
       "- Computes properties of each segmented nucleus, such as mean intensity, area (size), and eccentricity (shape), using `skimage.measure.regionprops`.\n",
       "- Outputs these properties to the console.\n",
       "- Optionally visualizes the segmentation overlaid on the original image.\n",
       "\n",
       "Ensure to replace `'path/to/your/image.tif'` with the actual path to your image file. Additionally, the script assumes you have installed the `stardist`, `numpy`, `matplotlib`, and `scikit-image` libraries. You can install them using `pip` if needed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Use the StarDist algorithm for segmenting the nuclei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f1a50-6037-4859-b7b9-46f46732f2d3",
   "metadata": {},
   "source": [
    "## Exercise: basic\n",
    "\n",
    "Load an image of your choice with nuclei staining ([example](https://github.com/haesleinhuepf/BioImageAnalysisNotebooks/blob/main/data/nuclei.tif)). Ask the LLM to use Otsu-Thresholding and Connected-Component Labeling for segmenting the nuclei. Make the code work!\n",
    "\n",
    "## Exercise: advanced\n",
    "Load an image of your choice showing cells with membrane staining ([example](https://github.com/haesleinhuepf/BioImageAnalysisNotebooks/blob/main/data/membranes_2d.tif)) and ask the LLM to generate code for using [CellPose](https://github.com/MouseLand/cellpose) for segmenting the cells. Follow the installation instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed19665-0251-41c8-8305-8675162aedbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Kernel (gpt-4o-2024-08-06)",
   "language": "prompt",
   "name": "llm-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "prompt"
   },
   "mimetype": "text/x-prompt",
   "name": "prompt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
