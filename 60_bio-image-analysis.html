

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Analysing image data &#8212; Prompt Engineering Basics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '60_bio-image-analysis';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Imprint" href="imprint.html" />
    <link rel="prev" title="Data analysis" href="50_data_analysis.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Prompt Engineering Basics
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="10_prompting.html">Prompting language models</a></li>
<li class="toctree-l1"><a class="reference internal" href="20_use_cases.html">Use cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="30_prompt_engineering.html">Prompt Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="40_code_generation.html">Code generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="50_data_analysis.html">Data analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Analysing image data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://zenodo.org/records/13336076">Download Slides</a></li>
<li class="toctree-l1"><a class="reference external" href="https://creativecommons.org/licenses/by/4.0/">License CC-BY 4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="imprint.html">Imprint</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ScaDS/generative-ai-notebooks" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ScaDS/generative-ai-notebooks/issues/new?title=Issue%20on%20page%20%2F60_bio-image-analysis.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/60_bio-image-analysis.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Analysing image data</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scientific-image-analysis-using-deep-learning">Scientific image analysis using deep learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modifying-code-style">Modifying code style</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-terms">Technical terms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-basic">Exercise: basic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-advanced">Exercise: advanced</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="analysing-image-data">
<h1>Analysing image data<a class="headerlink" href="#analysing-image-data" title="Permalink to this heading">#</a></h1>
<p>LLMs can also assist you in analysing image data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-prompt notranslate"><div class="highlight"><pre><span></span>Write code for analysing an image.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<p>To analyze an image programmatically, you can use libraries like OpenCV and PIL (Pillow) in Python. Below is a sample code that demonstrates how to load an image, convert it to grayscale, and detect edges using OpenCV:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Load an image from file</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;path_to_your_image.jpg&#39;</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>

<span class="c1"># Convert the image to grayscale</span>
<span class="n">gray_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="c1"># Use Canny Edge Detection</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">Canny</span><span class="p">(</span><span class="n">gray_image</span><span class="p">,</span> <span class="n">threshold1</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">threshold2</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="c1"># Display the original image and the edge-detected image</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Edge Detected Image&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">Explanation:</p>
<ul class="simple">
<li><p><strong>OpenCV</strong>: A powerful library for computer vision tasks. We use it to load images and perform image processing operations.</p></li>
<li><p><strong>cv2.imread()</strong>: Reads an image from a file.</p></li>
<li><p><strong>cv2.cvtColor()</strong>: Converts the image from one color space to another, here from BGR to Grayscale.</p></li>
<li><p><strong>cv2.Canny()</strong>: Performs edge detection using the Canny algorithm.</p></li>
<li><p><strong>matplotlib.pyplot</strong>: Used here for displaying images.</p></li>
</ul>
<p class="rubric">Requirements:</p>
<ul>
<li><p>Ensure OpenCV and Matplotlib are installed. You can install them via pip if they are not already installed:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>opencv-python-headless<span class="w"> </span>matplotlib
</pre></div>
</div>
</li>
</ul>
<p>Replace <code class="docutils literal notranslate"><span class="pre">'path_to_your_image.jpg'</span></code> with the actual path to your image file. This code will display both the original and processed edge-detected images side by side. Adjust the <code class="docutils literal notranslate"><span class="pre">threshold1</span></code> and <code class="docutils literal notranslate"><span class="pre">threshold2</span></code> parameters in <code class="docutils literal notranslate"><span class="pre">cv2.Canny()</span></code> to fine-tune edge detection results based on specific needs or image characteristics.</p>
</div>
</div>
<section id="scientific-image-analysis-using-deep-learning">
<h2>Scientific image analysis using deep learning<a class="headerlink" href="#scientific-image-analysis-using-deep-learning" title="Permalink to this heading">#</a></h2>
<p>It might be important that you specify the desired profession and the goals of the analysis, what the images show and what kind of algorithm you want to use. Again, if you specify the task to weakly, the LLM may generate code that is good for anything or nothing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-prompt notranslate"><div class="highlight"><pre><span></span>You are a bio-image analyst.
You are about to analyse an image taken with a 
fluorescence microscope that shows nuclei in DAPI staining.
You should use Deep Learning to segment the nuclei in the image.
You should quantify intensity, size and shape of the segmented nuclei.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<p>To achieve this task, we’ll utilize a deep learning model, such as a U-Net, to perform semantic segmentation of the nuclei in the DAPI-stained image. Following segmentation, we’ll extract quantitative metrics like intensity, size, and shape.</p>
<p>Below is an example code to accomplish this task using Python and popular libraries such as TensorFlow/Keras for deep learning, OpenCV for image manipulation, and scikit-image for measurements.</p>
<p>Ensure you have these packages installed in your environment:</p>
<ul class="simple">
<li><p>TensorFlow: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">tensorflow</span></code></p></li>
<li><p>OpenCV: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">opencv-python</span></code></p></li>
<li><p>scikit-image: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">scikit-image</span></code></p></li>
<li><p>NumPy: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">numpy</span></code></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">measure</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="c1"># Load the pre-trained U-Net model</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;path_to_your_trained_model.h5&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Load and preprocess the input image</span>
<span class="k">def</span> <span class="nf">preprocess_image</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>  <span class="c1"># Resize to the model&#39;s expected input size</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span> <span class="o">/</span> <span class="mf">255.0</span>  <span class="c1"># Normalize the image</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Add batch and channel dimensions</span>

<span class="c1"># Predict and segment the nuclei</span>
<span class="k">def</span> <span class="nf">segment_nuclei</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">segmentation</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>  <span class="c1"># Threshold prediction</span>
    <span class="k">return</span> <span class="n">segmentation</span>

<span class="c1"># Quantify nuclei properties</span>
<span class="k">def</span> <span class="nf">quantify_nuclei_properties</span><span class="p">(</span><span class="n">segmentation</span><span class="p">,</span> <span class="n">original_image</span><span class="p">):</span>
    <span class="n">labeled_nuclei</span> <span class="o">=</span> <span class="n">measure</span><span class="o">.</span><span class="n">label</span><span class="p">(</span><span class="n">segmentation</span><span class="p">)</span>
    <span class="n">properties</span> <span class="o">=</span> <span class="n">measure</span><span class="o">.</span><span class="n">regionprops</span><span class="p">(</span><span class="n">labeled_nuclei</span><span class="p">,</span> <span class="n">intensity_image</span><span class="o">=</span><span class="n">original_image</span><span class="p">)</span>
    
    <span class="n">nucleus_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">prop</span> <span class="ow">in</span> <span class="n">properties</span><span class="p">:</span>
        <span class="n">nucleus_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;centroid&#39;</span><span class="p">:</span> <span class="n">prop</span><span class="o">.</span><span class="n">centroid</span><span class="p">,</span>
            <span class="s1">&#39;area&#39;</span><span class="p">:</span> <span class="n">prop</span><span class="o">.</span><span class="n">area</span><span class="p">,</span>
            <span class="s1">&#39;mean_intensity&#39;</span><span class="p">:</span> <span class="n">prop</span><span class="o">.</span><span class="n">mean_intensity</span><span class="p">,</span>
            <span class="s1">&#39;eccentricity&#39;</span><span class="p">:</span> <span class="n">prop</span><span class="o">.</span><span class="n">eccentricity</span><span class="p">,</span>
            <span class="s1">&#39;solidity&#39;</span><span class="p">:</span> <span class="n">prop</span><span class="o">.</span><span class="n">solidity</span>
        <span class="p">}</span>
        <span class="n">nucleus_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nucleus_info</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nucleus_data</span>

<span class="c1"># Main analysis</span>
<span class="k">def</span> <span class="nf">analyze_image</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>
    <span class="n">original_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_GRAYSCALE</span><span class="p">)</span>  <span class="c1"># Load the original image for intensity measurements</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">preprocess_image</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="n">segmentation</span> <span class="o">=</span> <span class="n">segment_nuclei</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    
    <span class="c1"># Upscale segmentation to the original image size for accurate measurement</span>
    <span class="n">segmentation</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">segmentation</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">),</span> <span class="n">original_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="n">nucleus_data</span> <span class="o">=</span> <span class="n">quantify_nuclei_properties</span><span class="p">(</span><span class="n">segmentation</span><span class="p">,</span> <span class="n">original_image</span><span class="p">)</span>
    
    <span class="c1"># Visualize the results</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">original_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Original Image&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">segmentation</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Nuclei Segmentation&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">nucleus_data</span>

<span class="c1"># Example usage</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;path_to_your_dapi_image.png&#39;</span>
<span class="n">nuclei_properties</span> <span class="o">=</span> <span class="n">analyze_image</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nuclei_properties</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Explanation:</p>
<ul class="simple">
<li><p><strong>Preprocessing:</strong> We load the image in grayscale and normalize its pixel values to between 0 and 1.</p></li>
<li><p><strong>Deep Learning Prediction:</strong> The image is passed through a U-Net model, which generates a binary mask (segmentation) of the nuclei.</p></li>
<li><p><strong>Labeling and Properties Extraction:</strong> The <code class="docutils literal notranslate"><span class="pre">skimage.measure.label</span></code> function is used to label connected components in the segmentation mask. We then use <code class="docutils literal notranslate"><span class="pre">regionprops</span></code> to calculate properties such as area, mean intensity, eccentricity, and solidity for each labeled nucleus.</p></li>
<li><p><strong>Visualization and Results:</strong> The original and segmented images are displayed, and a list of dictionaries containing the extracted properties for each nucleus is returned and printed.</p></li>
</ul>
<p>Make sure to replace the placeholders (<code class="docutils literal notranslate"><span class="pre">path_to_your_trained_model.h5</span></code>, <code class="docutils literal notranslate"><span class="pre">path_to_your_dapi_image.png</span></code>) with actual paths to your model and image files. You might need to adjust the image resizing steps depending on your model’s expected input size.</p>
</div>
</div>
</section>
<section id="modifying-code-style">
<h2>Modifying code style<a class="headerlink" href="#modifying-code-style" title="Permalink to this heading">#</a></h2>
<p>As shown earlier, you can ask the LLM to change the style of the code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-prompt notranslate"><div class="highlight"><pre><span></span>Make the code as short as possible and do not use functions.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<p>To segment and analyze nuclei in a DAPI-stained fluorescence microscope image using deep learning without defining functions explicitly, you can use a pre-trained deep learning model like U-Net for segmentation and then quantify intensity, size, and shape using libraries such as NumPy and OpenCV. Here’s a concise Python script using PyTorch and OpenCV:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">skimage.measure</span> <span class="kn">import</span> <span class="n">label</span><span class="p">,</span> <span class="n">regionprops</span>

<span class="c1"># Load image and pre-trained U-Net model</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="s1">&#39;path_to_image.png&#39;</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;path_to_model.pth&#39;</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;L&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Preprocess the image</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>  <span class="c1"># Resize to match the model input if necessary</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">])</span>
<span class="p">])</span>

<span class="n">input_image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Segment the nuclei</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
    <span class="n">segmented</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span>  <span class="c1"># Threshold the output</span>

<span class="c1"># Convert segmentation to binary image</span>
<span class="n">segmented_img</span> <span class="o">=</span> <span class="n">segmented</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span>

<span class="c1"># Label and analyze properties of segmented nuclei</span>
<span class="n">labeled_img</span> <span class="o">=</span> <span class="n">label</span><span class="p">(</span><span class="n">segmented_img</span><span class="p">)</span>
<span class="n">props</span> <span class="o">=</span> <span class="n">regionprops</span><span class="p">(</span><span class="n">labeled_img</span><span class="p">,</span> <span class="n">intensity_image</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>

<span class="c1"># Quantify attributes</span>
<span class="k">for</span> <span class="n">prop</span> <span class="ow">in</span> <span class="n">props</span><span class="p">:</span>
    <span class="n">intensity</span> <span class="o">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">mean_intensity</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">area</span>
    <span class="n">eccentricity</span> <span class="o">=</span> <span class="n">prop</span><span class="o">.</span><span class="n">eccentricity</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Intensity: </span><span class="si">{</span><span class="n">intensity</span><span class="si">}</span><span class="s1">, Size: </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s1">, Eccentricity: </span><span class="si">{</span><span class="n">eccentricity</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Note</strong>: This example assumes that you have a pre-trained U-Net model saved as a <code class="docutils literal notranslate"><span class="pre">.pth</span></code> file and an input image. You may need to adjust the transforms, model path, and image path appropriately.</p>
<p><strong>Additional Considerations</strong>:</p>
<ul class="simple">
<li><p>Ensure that the input dimensions match the model’s expected input dimensions (resize if necessary).</p></li>
<li><p>If using a different framework (e.g., TensorFlow), adjust the loading and inference code accordingly.</p></li>
<li><p>Pre-trained models for segmentation can often be found on platforms like PyTorch Hub or model zoos. These models should be compatible with your analytical goals.</p></li>
</ul>
</div>
</div>
</section>
<section id="technical-terms">
<h2>Technical terms<a class="headerlink" href="#technical-terms" title="Permalink to this heading">#</a></h2>
<p>If you know basics of image analysis and deep learning, you can guide the LLM in generating the code even closer. It needs this guidance, because it cannot see the image and it does not have expertise such as which algorithm to use (e.g. <a class="reference external" href="https://github.com/stardist/stardist">StarDist</a>) for which kind of image. This may change obviously as LLMs are an active research field.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-prompt notranslate"><div class="highlight"><pre><span></span>Use the StarDist algorithm for segmenting the nuclei.
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<p>Certainly! Below is a concise code snippet that uses the StarDist algorithm to segment nuclei in an image, then quantifies their intensity, size, and shape. This example assumes you have the necessary libraries installed and a pre-trained model available for use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">stardist.models</span> <span class="kn">import</span> <span class="n">StarDist2D</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span><span class="p">,</span> <span class="n">measure</span>

<span class="c1"># Load the pre-trained StarDist model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">StarDist2D</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;2D_versatile_fluo&#39;</span><span class="p">)</span>

<span class="c1"># Read the image with DAPI staining</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;path/to/your/image.tif&#39;</span><span class="p">)</span>

<span class="c1"># Segment nuclei using StarDist</span>
<span class="n">labels</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_instances</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Quantify intensity, size, and shape</span>
<span class="n">properties</span> <span class="o">=</span> <span class="n">measure</span><span class="o">.</span><span class="n">regionprops</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">intensity_image</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Extract and print properties</span>
<span class="k">for</span> <span class="n">prop</span> <span class="ow">in</span> <span class="n">properties</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nucleus </span><span class="si">{</span><span class="n">prop</span><span class="o">.</span><span class="n">label</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Intensity: </span><span class="si">{</span><span class="n">prop</span><span class="o">.</span><span class="n">mean_intensity</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Size (area): </span><span class="si">{</span><span class="n">prop</span><span class="o">.</span><span class="n">area</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Eccentricity (shape): </span><span class="si">{</span><span class="n">prop</span><span class="o">.</span><span class="n">eccentricity</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Optionally, display the segmented nuclei</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>This script does the following:</p>
<ul class="simple">
<li><p>Loads a pre-trained StarDist model for 2D fluorescence microscopy images.</p></li>
<li><p>Reads the input image.</p></li>
<li><p>Segments the nuclei using the StarDist model.</p></li>
<li><p>Computes properties of each segmented nucleus, such as mean intensity, area (size), and eccentricity (shape), using <code class="docutils literal notranslate"><span class="pre">skimage.measure.regionprops</span></code>.</p></li>
<li><p>Outputs these properties to the console.</p></li>
<li><p>Optionally visualizes the segmentation overlaid on the original image.</p></li>
</ul>
<p>Ensure to replace <code class="docutils literal notranslate"><span class="pre">'path/to/your/image.tif'</span></code> with the actual path to your image file. Additionally, the script assumes you have installed the <code class="docutils literal notranslate"><span class="pre">stardist</span></code>, <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>, and <code class="docutils literal notranslate"><span class="pre">scikit-image</span></code> libraries. You can install them using <code class="docutils literal notranslate"><span class="pre">pip</span></code> if needed.</p>
</div>
</div>
</section>
<section id="exercise-basic">
<h2>Exercise: basic<a class="headerlink" href="#exercise-basic" title="Permalink to this heading">#</a></h2>
<p>Load an image of your choice with nuclei staining (<a class="reference external" href="https://github.com/haesleinhuepf/BioImageAnalysisNotebooks/blob/main/data/nuclei.tif">example</a>). Ask the LLM to use Otsu-Thresholding and Connected-Component Labeling for segmenting the nuclei. Make the code work!</p>
</section>
<section id="exercise-advanced">
<h2>Exercise: advanced<a class="headerlink" href="#exercise-advanced" title="Permalink to this heading">#</a></h2>
<p>Load an image of your choice showing cells with membrane staining (<a class="reference external" href="https://github.com/haesleinhuepf/BioImageAnalysisNotebooks/blob/main/data/membranes_2d.tif">example</a>) and ask the LLM to generate code for using <a class="reference external" href="https://github.com/MouseLand/cellpose">CellPose</a> for segmenting the cells. Follow the installation instructions.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "llm-kernel"
        },
        kernelOptions: {
            name: "llm-kernel",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'llm-kernel'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="50_data_analysis.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Data analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="imprint.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Imprint</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scientific-image-analysis-using-deep-learning">Scientific image analysis using deep learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modifying-code-style">Modifying code style</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-terms">Technical terms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-basic">Exercise: basic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-advanced">Exercise: advanced</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on 2024-08-17.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>